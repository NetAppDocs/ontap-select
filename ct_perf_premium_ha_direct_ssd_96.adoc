---
sidebar: sidebar
permalink: ct_perf_premium_ha_direct_ssd_96.html
keywords: ontap select, performance
summary: Performance information for ONTAP Select 9.6 performance - premium HA direct-attached SSD storage.
---

= ONTAP Select 9.6 performance: Premium HA direct-attached SSD storage
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
Performance information for the reference platform.

== Reference platform

ONTAP Select 9.6 (Premium XL) Hardware (per Node)

* FUJITSU PRIMERGY RX2540 M4:
** Intel(R) Xeon(R) Gold 6142b CPU at 2.6 GHz
** 32 physical cores (16 x 2 sockets), 64 logical
** 256 GB RAM
** Drives per host: 24 960GB SSD
** ESX 6.5U1

Client hardware
* 5 x NFSv3 IBM 3550m4 clients

Configuration information
* SW RAID 1 x 9 + 2 RAID-DP (11 drives)
* 22+1 RAID-5 (RAID-0 in ONTAP) / RAID cache NVRAM
* No storage efficiency features in use (compression, deduplication, Snapshot copies, SnapMirror, and so on)

The following table lists the throughput measured against read/write workloads on an HA pair of ONTAP Select Premium nodes using both software RAID and hardware RAID. Performance measurements were taken using the SIO load-generating tool.

*Performance results for a single node (part of a four-node medium instance) ONTAP Select 9.5 cluster on DAS (SSD) with software RAID and hardware RAID*

[cols=6*,options="header"]
|===
| Description | Sequential Read 64KiB | Sequential Write 64KiB | Random Read 8KiB | Random Write 8KiB | Random WR/ RD (50/50) 8KiB
| ONTAP 9.6 Select Large instance with DAS (SSD) software RAID | 2171 MiBps | 559 MiBps | 954 MiBps | 394 MiBps | 564 MiBps
| ONTAP 9.6 Select Medium instance with DAS (SSD) software RAID | 2090 MiBps | 592 MiBps | 677 MiBps | 335 MiBps | 441 3MiBps
| ONTAP 9.6 Select Medium instance with DAS (SSD) hardware RAID | 2038 MiBps | 520 MiBps | 578 MiBps | 325 MiBps | 399 MiBps
|===

=== 64K sequential read

Details:

* SIO direct I/O enabled
* 2 nodes
* 2 x data NIC per node
* 1 x data aggregate per node (2TB hardware RAID), (8TB software RAID)
* 64 SIO procs, 1 thread per proc
* 32 volumes per node
* 1 x files per proc; files are 12000MB each

=== 64K sequential write

Details:

* SIO direct I/O enabled
* 2 nodes
* 2 x data NIC per node
* 1 x data aggregate per node (2TB hardware RAID), (4TB software RAID)
* 128 SIO procs, 1 thread per proc
* volumes per node 32 (hardware RAID), 16 (software RAID)
* 1 x files per proc; files are 30720MB each

=== 8K random read

Details:

* SIO direct I/O enabled
* 2 nodes
* 2 x data NIC per node
* 1 x data aggregate per node (2TB hardware RAID), (4TB software RAID)
* 64 SIO procs, 8 threads per proc
* volumes per node 32
* 1 x files per proc; files are 12228MB each

=== 8K random write

Details:

* SIO direct I/O enabled
* 2 nodes
* 2 x data NIC per node
* 1 x data aggregate per node (2TB hardware RAID), (4TB software RAID)
* 64 SIO procs, 8 threads per proc
* volumes per node 32
* 1 x files per proc; files are 8192MB each

=== 8K random 50% write 50% read

Details:

* SIO direct I/O enabled
* 2 nodes
* 2 x data NIC per node
* 1 x data aggregate per node (2TB hardware RAID), (4TB software RAID)
* 64 SIO proc208 threads per proc
* volumes per node 32
* 1 x files per proc; files are 12228MB each
